{"cells":[{"cell_type":"markdown","source":["This code is modified from the code at the below link.\n","\n","https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb"],"metadata":{"id":"_BEpQPisq4SM"}},{"cell_type":"markdown","metadata":{"id":"YQ7C_QHuDiyk"},"source":["## Part 0: Prerequisites:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5651,"status":"ok","timestamp":1648071163804,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"},"user_tz":240},"id":"I93X10xXDiym","outputId":"3048ce07-305a-45cc-ee86-afed6858fd66"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}],"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","# Commonly used modules\n","import numpy as np\n","import os\n","import sys\n","\n","# Images, plots, display, and visualization\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import cv2\n","import IPython\n","from six.moves import urllib\n","\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"x0wq-eYvDiyx"},"source":["## Classification of MNIST with Convolutional Neural Networks\n","\n","Goal is to build a convolutional neural network (CNN) classifier to classify images of handwritten digits in the MNIST dataset."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Hd_j8M1EDiyx","executionInfo":{"status":"ok","timestamp":1648071163804,"user_tz":240,"elapsed":14,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"}}},"outputs":[],"source":["# Set common constants\n","this_repo_url = 'https://github.com/lexfridman/mit-deep-learning/raw/master/'\n","this_tutorial_url = this_repo_url + 'tutorial_deep_learning_basics'"]},{"cell_type":"markdown","metadata":{"id":"_VLM5xadDiyy"},"source":["The MNIST dataset contains 70,000 grayscale images of handwritten digits at a resolution of 28 by 28 pixels. The task is to take one of these images as input and predict the most likely digit contained in the image (along with a relative confidence in this prediction):\n","\n","Now, we load the dataset. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":733,"status":"ok","timestamp":1648071164527,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"},"user_tz":240},"id":"A9NWNeM3Diyy","outputId":"4fd74300-cb0d-4de0-c214-712e7ae5368f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n","\n","# reshape images to specify that it's a single channel\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n","test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"]},{"cell_type":"markdown","metadata":{"id":"ZtLITddoDiyz"},"source":["We scale these values to a range of 0 to 1 before feeding to the neural network model. For this, we divide the values by 255. It's important that the *training set* and the *testing set* are preprocessed in the same way:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"t8e134kUDiyz","executionInfo":{"status":"ok","timestamp":1648071164932,"user_tz":240,"elapsed":231,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"}}},"outputs":[],"source":["def preprocess_images(imgs): # should work for both a single image and multiple images\n","    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n","    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n","    return imgs / 255.0\n","\n","train_images = preprocess_images(train_images)\n","test_images = preprocess_images(test_images)"]},{"cell_type":"markdown","metadata":{"id":"c17Vk5NtDiy0"},"source":["Display the first 5 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1648071165590,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"},"user_tz":240},"id":"e_Yre8k-Diy1","outputId":"047cf3d3-2b9b-4ef1-ce32-de91b058dcb3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x144 with 5 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.figure(figsize=(10,2))\n","for i in range(5):\n","    plt.subplot(1,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n","    plt.xlabel(train_labels[i])"]},{"cell_type":"markdown","metadata":{"id":"1D8kn90yDiy1"},"source":["### Build the model\n","\n","Building the neural network requires configuring the layers of the model, then compiling the model. In many cases, this can be reduced to simply stacking together layers:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"qVJYxz91Diy1","executionInfo":{"status":"ok","timestamp":1648071165985,"user_tz":240,"elapsed":399,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"}}},"outputs":[],"source":["model = keras.Sequential()\n","# 32 convolution filters used each of size 3x3\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n","# 64 convolution filters used each of size 3x3\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","# choose the best features via pooling\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","# randomly turn neurons on and off to improve convergence\n","model.add(Dropout(0.25))\n","# flatten since too many dimensions, we only want a classification output\n","model.add(Flatten())\n","# fully connected to get all relevant data\n","model.add(Dense(128, activation='relu'))\n","# one more dropout\n","model.add(Dropout(0.5))\n","# output a softmax to squash the matrix into output probabilities\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"MTudvBObDiy2"},"source":["Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n","\n","* *Loss function* - measures how accurate the model is during training, we want to minimize this with the optimizer.\n","* *Optimizer* - how the model is updated based on the data it sees and its loss function.\n","* *Metrics* - used to monitor the training and testing steps. \"accuracy\" is the fraction of images that are correctly classified."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zpiK6IpPDiy2","executionInfo":{"status":"ok","timestamp":1648071165986,"user_tz":240,"elapsed":10,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"}}},"outputs":[],"source":["model.compile(optimizer=tf.optimizers.Adam(), \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"dY1JevlNDiy2"},"source":["### Train the model\n","\n","Training the neural network model requires the following steps:\n","\n","1. Feed the training data to the model—in this example, the `train_images` and `train_labels` arrays.\n","2. The model learns to associate images and labels.\n","3. We ask the model to make predictions about a test set—in this example, the `test_images` array. We verify that the predictions match the labels from the `test_labels` array. \n","\n","To start training,  call the `model.fit` method—the model is \"fit\" to the training data:"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":803662,"status":"ok","timestamp":1648071969643,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"},"user_tz":240},"id":"wuJBOd1dDiy3","outputId":"37380b3d-55fa-44bf-a8a6-7855ae387190"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 154s 81ms/step - loss: 0.1837 - accuracy: 0.9447\n","Epoch 2/5\n","1875/1875 [==============================] - 147s 78ms/step - loss: 0.0786 - accuracy: 0.9767\n","Epoch 3/5\n","1875/1875 [==============================] - 147s 79ms/step - loss: 0.0597 - accuracy: 0.9818\n","Epoch 4/5\n","1875/1875 [==============================] - 148s 79ms/step - loss: 0.0496 - accuracy: 0.9846\n","Epoch 5/5\n","1875/1875 [==============================] - 148s 79ms/step - loss: 0.0411 - accuracy: 0.9874\n"]}],"source":["history = model.fit(train_images, train_labels, epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"OOuUUUlHDiy3"},"source":["As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 98.68% on the training data."]},{"cell_type":"markdown","metadata":{"id":"a5d8QRRnDiy8"},"source":["### Evaluate accuracy\n","\n","Next, compare how the model performs on the test dataset:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6065,"status":"ok","timestamp":1648071975701,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"},"user_tz":240},"id":"nm9Cz1u8Diy8","outputId":"290fa083-c839-4630-93a5-5f64332dc572"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 28, 28, 1)\n","313/313 [==============================] - 6s 19ms/step - loss: 0.0293 - accuracy: 0.9905\n","Test accuracy: 0.9904999732971191\n"]}],"source":["print(test_images.shape)\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","print('Test accuracy:', test_acc)"]},{"cell_type":"markdown","metadata":{"id":"x8fBfUcbDiy9"},"source":["Often times, the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy is an example of *overfitting*. In our case, the accuracy is better at 99.19%! This is, in part, due to successful regularization accomplished with the Dropout layers."]},{"cell_type":"code","source":["test_predictions = model.predict(test_images)\n","from sklearn.metrics import confusion_matrix\n","confusion = confusion_matrix(test_labels, np.argmax(test_predictions,axis=1))\n","print(confusion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CC33EKOpYQ4Q","executionInfo":{"status":"ok","timestamp":1648071981273,"user_tz":240,"elapsed":5588,"user":{"displayName":"Ankit Sisodia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GileqfBKLHR-VioRr-FeKi8XXB7xpZCuSJHQXEP=s64","userId":"02762745324303511308"}},"outputId":"733f7b9b-eb14-46f9-812d-8a03d2d8a929"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 975    0    1    0    0    0    2    0    1    1]\n"," [   0 1132    1    1    0    1    0    0    0    0]\n"," [   2    2 1020    1    0    0    0    6    1    0]\n"," [   0    0    1 1002    0    4    0    2    1    0]\n"," [   0    0    0    0  977    0    3    0    1    1]\n"," [   1    0    0    4    0  886    1    0    0    0]\n"," [   6    3    0    0    1    2  945    0    1    0]\n"," [   0    3    3    1    0    0    0 1020    1    0]\n"," [   3    1    3    1    0    1    0    2  959    4]\n"," [   1    1    0    0    7    3    0    5    3  989]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"eF4fc9BbDiy-"},"source":["## Acknowledgements\n","\n","The contents of this tutorial is based on and inspired by the work of [TensorFlow team](https://www.tensorflow.org) (see their [Colab notebooks](https://www.tensorflow.org/tutorials/)), [MIT Human-Centered AI team](https://hcai.mit.edu), and individual pieces referenced in the [MIT Deep Learning](https://deeplearning.mit.edu) course slides."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"MNIST Classification [Supervised Problem with Unstructured Data].ipynb","provenance":[{"file_id":"https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb","timestamp":1643849339674}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}